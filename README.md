# progettoDLA
Materiale del progetto per il corso di Deep Learning and Applications

# Prerequisiti ed installazione
- Python >= 3.8

### 1. Clonazione della repository

```bash
git clone https://github.com/concasfilippo/progettoDLA.git
cd nome-repo
```



### 2. Crea un ambiente virtuale

### ü™ü Windows (CMD o PowerShell)

```bash
python -m venv venv
venv\Scripts\activate
```

### üçé macOS

```bash
python3 -m venv venv
source venv/bin/activate
```

### üêß Ubuntu/Linux

```bash
sudo apt update
sudo apt install python3-venv -y
python3 -m venv venv
source venv/bin/activate
```

---

### 3. Installazione delle dipendenze

```bash
pip install -r requirements.txt
```



### 4. Avvio di Jupyter Notebook

### Se Jupyter non √® installato:

```bash
pip install notebook
```

### Avvia il server Jupyter:

```bash
jupyter notebook
```


# Installazione
pip install -r requirements.txt

# Struttura del progetto

Dataset (immagini e testo) non caricato. I file sono presenti nel sito degli organizzatori, che lo rendono diponibile dopo una registrazione automatica ([Link SemEval2024](https://propaganda.math.unipd.it/semeval2024task4/)). Presenta la seguente struttura, che si pu√≤ replicare con lo script pre_processing.ipynb indicato di sotto:
- /pre-processing/datasets/train/[classe]/ #tutte le immagini di classe [classe] per il training
- /pre-processing/datasets/val/[classe]/ #tutte le immagini di classe [classe] per il validation set
- /pre-processing/datasets/test/[classe]/ #tutte le immagini di classe [classe] per il test set
- /pre-processing/datasets/train.json  # json con i dati degli item di train
- /pre-processing/datasets/val.json   # json con i dati degli item di train
- /pre-processing/datasets/test.json   # json con i dati degli item di train

Pre-processing ed analisi del dataset:
- /pre-processing/pre_processing.ipynb 
    Si tratta di uno script per 
    - Trasformare le immagini e le descrizioni in un formato pi√π agevole per lo studio;
    - Analizzare la distribuzione degli item per classe e visualizzarne qualche esempio;
    - Osservare la distribuzione della lunghezza dei testi, sia in formato grezzo sia in base alla tokenizzazione dei modelli pre-trained usati;
    - Extra: visualizzazione delle wordcloud

Modelli usati:

(clip)
- /models/model_clip-vit-large-patch14_GridSearch.ipynb
    Si tratta di uno script con cui √® stata eseguita la Grid Search usando come modello clip vit lagre patch 14
- /models/clip-vit-large-patch14_GS.csv sono i risultati della Grid Search
- /models/model_clip_vit_large_patch14_best_analysis.ipynb
    Si tratta dello script con cui √® stato analizzato il modello con la configurazione che ha restituito i risultati migliori nella Grid Search, e su cui sono stati fatti i test con le varianti di data Augmentation

(openclip)
- /models/model_openclip_rn50quickgelu_GridSearch.ipynb
    Si tratta di uno script con cui √® stata eseguita la Grid Search usando come modello open clip resnet 50 quickgelu ed uno script che non esegue la grid search

- /models/saves_models/ #cartella con alcuni modelli performanti scelti, lanciabili con lo script indicato precedentemente

- /models/model_openclip_rn50quickgelu_best_analysis.ipynb
    Analisi del modello migliore sia da zero che caricando il modello

- /models/model_openclip_rn50quickgelu_best_analysis_DA.ipynb
    Questo script serve per addestarre o caricare i modello con Data Augmentation con open clip rn 50 quickgelu

- /models/model_openclip_rn50quickgelu_kfold_e_confrontoConDA.ipynb
    Baseline per il confronto con la varianete con data augmentation con t-test

- /models/result_analisys.ipynb 
    Script per analizzare le performance dei risultati dei due modelli

(modelli di fusione esplicita degli embeddings)
- /models/model_multimodal_fusion_classifier.ipynb
    Questo script offre la possibilit√† di provre ogni combinazione di fusione esplicita degli embeddings e classificatore tra
        Tra le strategie di fusione: Concatenazione, Layer di attenzione (Multi Head Attention) e Transformer (quindi cross modale)
        Tra le strategie di classificazione: MLP e Transformer


I file clip-vit-large-patch14_GS.csv e openclip-rn50quickgelu_GS.csv indicano i risultati ottenuti dagli esperimenti con la GridSearch





